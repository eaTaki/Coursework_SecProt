{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following text was encrypted using the substitution cipher. Please decode it using any method you find adequate. After you found a solution, please describe how you analyzed the text.\n",
    "\n",
    "---\n",
    "\n",
    "The first thing we notice is that the text seems to be in MORSE code. By a little further exploration, we also realise there is only letters, so we proceed to obtain the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KQAVDUWRJVXUHDXYZGYWKWZWKRQAKUHFVKYXPFWHRERIFQAVDUWKQJKQSHKAHZQKWYRIUNXKQWFOWXVFVFUNXAFESKWHWHFAKUHFVWFOWKQXEFIKQFEPXQQFVSKWHWHFHFNURIXMFDWHFZQKWYPXDGFYKQJNFNFWWFVYWHFPRYWARPPRQUXKVYRINFWWFVYWVKUNFWYRINFWWFVYPKOWZVFYRIWHFXGRBFXQEYRIRVWHWHFVFAFKBFVEFAKUHFVYWHFWFOWGDUFVIRVPKQJWHFKQBFVYFYZGYWKWZWKRQUVRAFYYWRFOWVXAWWHFRVKJKQXNPFYYXJF\n",
      "YZGYWKWZWKRQAKUHFVYAXQGFARPUXVFESKWHWVXQYURYKWKRQAKUHFVYKQXWVXQYURYKWKRQAKUHFVWHFZQKWYRIWHFUNXKQWFOWXVFVFXVVXQJFEKQXEKIIFVFQWXQEZYZXNNDCZKWFARPUNFORVEFVGZWWHFZQKWYWHFPYFNBFYXVFNFIWZQAHXQJFEGDARQWVXYWKQXYZGYWKWZWKRQAKUHFVWHFZQKWYRIWHFUNXKQWFOWXVFVFWXKQFEKQWHFYXPFYFCZFQAFKQWHFAKUHFVWFOWGZWWHFZQKWYWHFPYFNBFYXVFXNWFVFE\n",
      "UNFXYFEFAREFWHKYWFOWZYKQJXQDPFWHREDRZIKQEXEFCZXWFDRZSKNNIKJZVFRZWWHXWWHFWFOWSXYFQAVDUWFEZYKQJWHFYZGYWKWZWKRQAKUHFVXIWFVDRZIRZQEXYRNZWKRQUNFXYFEFYAVKGFHRSDRZXQXNDTFEWHFWFOWHKQWDRZPXDZYFXQDUVRJVXPRVYKPUNDARZQWWHFIVFCZFQAKFYRIXNNWHFUKAWZVFYWHXWXUUFXVSKWHKQWHFWFOWHXBFIZQ\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "\n",
    "data = open('ex2_raw.txt', 'r').read()\n",
    "data = data.split('\\n')\n",
    "data = [x.split() for x in data]\n",
    "data = [[morse_code[i] for i in x] for x in data]\n",
    "data = [\"\".join(x) for x in data]\n",
    "for x in data:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how we apparently have three sentences of random characters. \n",
    "We first try to decypher the texts with the caesar cypher by attempting all 26 combinations on one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tUNFXYFEFAREFWHKYWFOWZYKQJXQDPFWHREDRZIKQEXEFCZXWFDRZSKNNIKJZVFRZWWHXWWHFWFOWSXYFQAVDUWFEZYKQJWHFYZGYWKWZWKRQAKUHFVXIWFVDRZIRZQEXYRNZWKRQUNFXYFEFYAVKGFHRSDRZXQXNDTFEWHFWFOWHKQWDRZPXDZYFXQDUVRJVXPRVYKPUNDARZQWWHFIVFCZFQAKFYRIXNNWHFUKAWZVFYWHXWXUUFXVSKWHKQWHFWFOWHXBFIZQ\n",
      "1:\tTMEWXEDEZQDEVGJXVENVYXJPIWPCOEVGQDCQYHJPDWDEBYWVECQYRJMMHJIYUEQYVVGWVVGEVENVRWXEPZUCTVEDYXJPIVGEXYFXVJVYVJQPZJTGEUWHVEUCQYHQYPDWXQMYVJQPTMEWXEDEXZUJFEGQRCQYWPWMCSEDVGEVENVGJPVCQYOWCYXEWPCTUQIUWOQUXJOTMCZQYPVVGEHUEBYEPZJEXQHWMMVGETJZVYUEXVGWVWTTEWURJVGJPVGEVENVGWAEHYP\n",
      "2:\tSLDVWDCDYPCDUFIWUDMUXWIOHVOBNDUFPCBPXGIOCVCDAXVUDBPXQILLGIHXTDPXUUFVUUFDUDMUQVWDOYTBSUDCXWIOHUFDWXEWUIUXUIPOYISFDTVGUDTBPXGPXOCVWPLXUIPOSLDVWDCDWYTIEDFPQBPXVOVLBRDCUFDUDMUFIOUBPXNVBXWDVOBSTPHTVNPTWINSLBYPXOUUFDGTDAXDOYIDWPGVLLUFDSIYUXTDWUFVUVSSDVTQIUFIOUFDUDMUFVZDGXO\n",
      "3:\tRKCUVCBCXOBCTEHVTCLTWVHNGUNAMCTEOBAOWFHNBUBCZWUTCAOWPHKKFHGWSCOWTTEUTTECTCLTPUVCNXSARTCBWVHNGTECVWDVTHTWTHONXHRECSUFTCSAOWFOWNBUVOKWTHONRKCUVCBCVXSHDCEOPAOWUNUKAQCBTECTCLTEHNTAOWMUAWVCUNARSOGSUMOSVHMRKAXOWNTTECFSCZWCNXHCVOFUKKTECRHXTWSCVTEUTURRCUSPHTEHNTECTCLTEUYCFWN\n",
      "4:\tQJBTUBABWNABSDGUSBKSVUGMFTMZLBSDNAZNVEGMATABYVTSBZNVOGJJEGFVRBNVSSDTSSDBSBKSOTUBMWRZQSBAVUGMFSDBUVCUSGSVSGNMWGQDBRTESBRZNVENVMATUNJVSGNMQJBTUBABUWRGCBDNOZNVTMTJZPBASDBSBKSDGMSZNVLTZVUBTMZQRNFRTLNRUGLQJZWNVMSSDBERBYVBMWGBUNETJJSDBQGWSVRBUSDTSTQQBTROGSDGMSDBSBKSDTXBEVM\n",
      "5:\tPIASTAZAVMZARCFTRAJRUTFLESLYKARCMZYMUDFLZSZAXUSRAYMUNFIIDFEUQAMURRCSRRCARAJRNSTALVQYPRAZUTFLERCATUBTRFRURFMLVFPCAQSDRAQYMUDMULZSTMIURFMLPIASTAZATVQFBACMNYMUSLSIYOAZRCARAJRCFLRYMUKSYUTASLYPQMEQSKMQTFKPIYVMULRRCADQAXUALVFATMDSIIRCAPFVRUQATRCSRSPPASQNFRCFLRCARAJRCSWADUL\n",
      "6:\tOHZRSZYZULYZQBESQZIQTSEKDRKXJZQBLYXLTCEKYRYZWTRQZXLTMEHHCEDTPZLTQQBRQQBZQZIQMRSZKUPXOQZYTSEKDQBZSTASQEQTQELKUEOBZPRCQZPXLTCLTKYRSLHTQELKOHZRSZYZSUPEAZBLMXLTRKRHXNZYQBZQZIQBEKQXLTJRXTSZRKXOPLDPRJLPSEJOHXULTKQQBZCPZWTZKUEZSLCRHHQBZOEUQTPZSQBRQROOZRPMEQBEKQBZQZIQBRVZCTK\n",
      "7:\tNGYQRYXYTKXYPADRPYHPSRDJCQJWIYPAKXWKSBDJXQXYVSQPYWKSLDGGBDCSOYKSPPAQPPAYPYHPLQRYJTOWNPYXSRDJCPAYRSZRPDPSPDKJTDNAYOQBPYOWKSBKSJXQRKGSPDKJNGYQRYXYRTODZYAKLWKSQJQGWMYXPAYPYHPADJPWKSIQWSRYQJWNOKCOQIKORDINGWTKSJPPAYBOYVSYJTDYRKBQGGPAYNDTPSOYRPAQPQNNYQOLDPADJPAYPYHPAQUYBSJ\n",
      "8:\tMFXPQXWXSJWXOZCQOXGORQCIBPIVHXOZJWVJRACIWPWXURPOXVJRKCFFACBRNXJROOZPOOZXOXGOKPQXISNVMOXWRQCIBOZXQRYQOCOROCJISCMZXNPAOXNVJRAJRIWPQJFROCJIMFXPQXWXQSNCYXZJKVJRPIPFVLXWOZXOXGOZCIOVJRHPVRQXPIVMNJBNPHJNQCHMFVSJRIOOZXANXURXISCXQJAPFFOZXMCSORNXQOZPOPMMXPNKCOZCIOZXOXGOZPTXARI\n",
      "9:\tLEWOPWVWRIVWNYBPNWFNQPBHAOHUGWNYIVUIQZBHVOVWTQONWUIQJBEEZBAQMWIQNNYONNYWNWFNJOPWHRMULNWVQPBHANYWPQXPNBNQNBIHRBLYWMOZNWMUIQZIQHVOPIEQNBIHLEWOPWVWPRMBXWYIJUIQOHOEUKWVNYWNWFNYBHNUIQGOUQPWOHULMIAMOGIMPBGLEURIQHNNYWZMWTQWHRBWPIZOEENYWLBRNQMWPNYONOLLWOMJBNYBHNYWNWFNYOSWZQH\n",
      "10:\tKDVNOVUVQHUVMXAOMVEMPOAGZNGTFVMXHUTHPYAGUNUVSPNMVTHPIADDYAZPLVHPMMXNMMXVMVEMINOVGQLTKMVUPOAGZMXVOPWOMAMPMAHGQAKXVLNYMVLTHPYHPGUNOHDPMAHGKDVNOVUVOQLAWVXHITHPNGNDTJVUMXVMVEMXAGMTHPFNTPOVNGTKLHZLNFHLOAFKDTQHPGMMXVYLVSPVGQAVOHYNDDMXVKAQMPLVOMXNMNKKVNLIAMXAGMXVMVEMXNRVYPG\n",
      "11:\tJCUMNUTUPGTULWZNLUDLONZFYMFSEULWGTSGOXZFTMTUROMLUSGOHZCCXZYOKUGOLLWMLLWULUDLHMNUFPKSJLUTONZFYLWUNOVNLZLOLZGFPZJWUKMXLUKSGOXGOFTMNGCOLZGFJCUMNUTUNPKZVUWGHSGOMFMCSIUTLWULUDLWZFLSGOEMSONUMFSJKGYKMEGKNZEJCSPGOFLLWUXKUROUFPZUNGXMCCLWUJZPLOKUNLWMLMJJUMKHZLWZFLWULUDLWMQUXOF\n",
      "12:\tIBTLMTSTOFSTKVYMKTCKNMYEXLERDTKVFSRFNWYESLSTQNLKTRFNGYBBWYXNJTFNKKVLKKVTKTCKGLMTEOJRIKTSNMYEXKVTMNUMKYKNKYFEOYIVTJLWKTJRFNWFNESLMFBNKYFEIBTLMTSTMOJYUTVFGRFNLELBRHTSKVTKTCKVYEKRFNDLRNMTLERIJFXJLDFJMYDIBROFNEKKVTWJTQNTEOYTMFWLBBKVTIYOKNJTMKVLKLIITLJGYKVYEKVTKTCKVLPTWNE\n",
      "13:\tHASKLSRSNERSJUXLJSBJMLXDWKDQCSJUERQEMVXDRKRSPMKJSQEMFXAAVXWMISEMJJUKJJUSJSBJFKLSDNIQHJSRMLXDWJUSLMTLJXJMJXEDNXHUSIKVJSIQEMVEMDRKLEAMJXEDHASKLSRSLNIXTSUEFQEMKDKAQGSRJUSJSBJUXDJQEMCKQMLSKDQHIEWIKCEILXCHAQNEMDJJUSVISPMSDNXSLEVKAAJUSHXNJMISLJUKJKHHSKIFXJUXDJUSJSBJUKOSVMD\n",
      "14:\tGZRJKRQRMDQRITWKIRAILKWCVJCPBRITDQPDLUWCQJQROLJIRPDLEWZZUWVLHRDLIITJIITRIRAIEJKRCMHPGIRQLKWCVITRKLSKIWILIWDCMWGTRHJUIRHPDLUDLCQJKDZLIWDCGZRJKRQRKMHWSRTDEPDLJCJZPFRQITRIRAITWCIPDLBJPLKRJCPGHDVHJBDHKWBGZPMDLCIITRUHROLRCMWRKDUJZZITRGWMILHRKITJIJGGRJHEWITWCITRIRAITJNRULC\n",
      "15:\tFYQIJQPQLCPQHSVJHQZHKJVBUIBOAQHSCPOCKTVBPIPQNKIHQOCKDVYYTVUKGQCKHHSIHHSQHQZHDIJQBLGOFHQPKJVBUHSQJKRJHVHKHVCBLVFSQGITHQGOCKTCKBPIJCYKHVCBFYQIJQPQJLGVRQSCDOCKIBIYOEQPHSQHQZHSVBHOCKAIOKJQIBOFGCUGIACGJVAFYOLCKBHHSQTGQNKQBLVQJCTIYYHSQFVLHKGQJHSIHIFFQIGDVHSVBHSQHQZHSIMQTKB\n",
      "16:\tEXPHIPOPKBOPGRUIGPYGJIUATHANZPGRBONBJSUAOHOPMJHGPNBJCUXXSUTJFPBJGGRHGGRPGPYGCHIPAKFNEGPOJIUATGRPIJQIGUGJGUBAKUERPFHSGPFNBJSBJAOHIBXJGUBAEXPHIPOPIKFUQPRBCNBJHAHXNDPOGRPGPYGRUAGNBJZHNJIPHANEFBTFHZBFIUZEXNKBJAGGRPSFPMJPAKUPIBSHXXGRPEUKGJFPIGRHGHEEPHFCUGRUAGRPGPYGRHLPSJA\n",
      "17:\tDWOGHONOJANOFQTHFOXFIHTZSGZMYOFQANMAIRTZNGNOLIGFOMAIBTWWRTSIEOAIFFQGFFQOFOXFBGHOZJEMDFONIHTZSFQOHIPHFTFIFTAZJTDQOEGRFOEMAIRAIZNGHAWIFTAZDWOGHONOHJETPOQABMAIGZGWMCONFQOFOXFQTZFMAIYGMIHOGZMDEASEGYAEHTYDWMJAIZFFQOREOLIOZJTOHARGWWFQODTJFIEOHFQGFGDDOGEBTFQTZFQOFOXFQGKORIZ\n",
      "18:\tCVNFGNMNIZMNEPSGENWEHGSYRFYLXNEPZMLZHQSYMFMNKHFENLZHASVVQSRHDNZHEEPFEEPNENWEAFGNYIDLCENMHGSYREPNGHOGESEHESZYISCPNDFQENDLZHQZHYMFGZVHESZYCVNFGNMNGIDSONPZALZHFYFVLBNMEPNENWEPSYELZHXFLHGNFYLCDZRDFXZDGSXCVLIZHYEEPNQDNKHNYISNGZQFVVEPNCSIEHDNGEPFEFCCNFDASEPSYEPNENWEPFJNQHY\n",
      "19:\tBUMEFMLMHYLMDORFDMVDGFRXQEXKWMDOYLKYGPRXLELMJGEDMKYGZRUUPRQGCMYGDDOEDDOMDMVDZEFMXHCKBDMLGFRXQDOMFGNFDRDGDRYXHRBOMCEPDMCKYGPYGXLEFYUGDRYXBUMEFMLMFHCRNMOYZKYGEXEUKAMLDOMDMVDORXDKYGWEKGFMEXKBCYQCEWYCFRWBUKHYGXDDOMPCMJGMXHRMFYPEUUDOMBRHDGCMFDOEDEBBMECZRDORXDOMDMVDOEIMPGX\n",
      "20:\tATLDELKLGXKLCNQECLUCFEQWPDWJVLCNXKJXFOQWKDKLIFDCLJXFYQTTOQPFBLXFCCNDCCNLCLUCYDELWGBJACLKFEQWPCNLEFMECQCFCQXWGQANLBDOCLBJXFOXFWKDEXTFCQXWATLDELKLEGBQMLNXYJXFDWDTJZLKCNLCLUCNQWCJXFVDJFELDWJABXPBDVXBEQVATJGXFWCCNLOBLIFLWGQLEXODTTCNLAQGCFBLECNDCDAALDBYQCNQWCNLCLUCNDHLOFW\n",
      "21:\tZSKCDKJKFWJKBMPDBKTBEDPVOCVIUKBMWJIWENPVJCJKHECBKIWEXPSSNPOEAKWEBBMCBBMKBKTBXCDKVFAIZBKJEDPVOBMKDELDBPBEBPWVFPZMKACNBKAIWENWEVJCDWSEBPWVZSKCDKJKDFAPLKMWXIWECVCSIYKJBMKBKTBMPVBIWEUCIEDKCVIZAWOACUWADPUZSIFWEVBBMKNAKHEKVFPKDWNCSSBMKZPFBEAKDBMCBCZZKCAXPBMPVBMKBKTBMCGKNEV\n",
      "22:\tYRJBCJIJEVIJALOCAJSADCOUNBUHTJALVIHVDMOUIBIJGDBAJHVDWORRMONDZJVDAALBAALJAJSAWBCJUEZHYAJIDCOUNALJCDKCAOADAOVUEOYLJZBMAJZHVDMVDUIBCVRDAOVUYRJBCJIJCEZOKJLVWHVDBUBRHXJIALJAJSALOUAHVDTBHDCJBUHYZVNZBTVZCOTYRHEVDUAALJMZJGDJUEOJCVMBRRALJYOEADZJCALBABYYJBZWOALOUALJAJSALBFJMDU\n",
      "23:\tXQIABIHIDUHIZKNBZIRZCBNTMATGSIZKUHGUCLNTHAHIFCAZIGUCVNQQLNMCYIUCZZKAZZKIZIRZVABITDYGXZIHCBNTMZKIBCJBZNZCZNUTDNXKIYALZIYGUCLUCTHABUQCZNUTXQIABIHIBDYNJIKUVGUCATAQGWIHZKIZIRZKNTZGUCSAGCBIATGXYUMYASUYBNSXQGDUCTZZKILYIFCITDNIBULAQQZKIXNDZCYIBZKAZAXXIAYVNZKNTZKIZIRZKAEILCT\n",
      "24:\tWPHZAHGHCTGHYJMAYHQYBAMSLZSFRHYJTGFTBKMSGZGHEBZYHFTBUMPPKMLBXHTBYYJZYYJHYHQYUZAHSCXFWYHGBAMSLYJHABIAYMYBYMTSCMWJHXZKYHXFTBKTBSGZATPBYMTSWPHZAHGHACXMIHJTUFTBZSZPFVHGYJHYHQYJMSYFTBRZFBAHZSFWXTLXZRTXAMRWPFCTBSYYJHKXHEBHSCMHATKZPPYJHWMCYBXHAYJZYZWWHZXUMYJMSYJHYHQYJZDHKBS\n",
      "25:\tVOGYZGFGBSFGXILZXGPXAZLRKYREQGXISFESAJLRFYFGDAYXGESATLOOJLKAWGSAXXIYXXIGXGPXTYZGRBWEVXGFAZLRKXIGZAHZXLXAXLSRBLVIGWYJXGWESAJSARFYZSOAXLSRVOGYZGFGZBWLHGISTESAYRYOEUGFXIGXGPXILRXESAQYEAZGYREVWSKWYQSWZLQVOEBSARXXIGJWGDAGRBLGZSJYOOXIGVLBXAWGZXIYXYVVGYWTLXILRXIGXGPXIYCGJAR\n"
     ]
    }
   ],
   "source": [
    "def cipher(message, K):\n",
    "    message = [ord(x) for x in message]\n",
    "    return \"\".join([chr(\n",
    "        ((x - (65 if (65 <= x <= 90) else 97) + K) % 26 + (65 if (65 <= x <= 90) else 97)) \n",
    "        if (65 <= x <= 90 or 97 <= x <= 122) else x) \n",
    "        for x in message])\n",
    "\n",
    "for i in range(26):\n",
    "    print(i, cipher(data[2], -i), sep=\":\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get no results with the caesar method os we are going to try to obtain the substitutions with frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               K         Q         A         V         D         U         W  \\\n",
      "Text 0  0.084592  0.057402  0.033233  0.072508  0.018127  0.039275  0.126888   \n",
      "Text 1  0.088608  0.082278  0.034810  0.066456  0.006329  0.034810  0.126582   \n",
      "Text 2  0.063670  0.056180  0.026217  0.041199  0.041199  0.033708  0.119850   \n",
      "\n",
      "               R         J         X  ...         P         E         I  \\\n",
      "Text 0  0.060423  0.018127  0.048338  ...  0.027190  0.018127  0.027190   \n",
      "Text 1  0.037975  0.006329  0.069620  ...  0.015823  0.025316  0.015823   \n",
      "Text 2  0.063670  0.014981  0.071161  ...  0.014981  0.033708  0.026217   \n",
      "\n",
      "               S         N         O         M         B         C         T  \n",
      "Text 0  0.009063  0.027190  0.015106  0.003021  0.009063       NaN       NaN  \n",
      "Text 1  0.003165  0.028481  0.012658       NaN  0.006329  0.006329       NaN  \n",
      "Text 2  0.014981  0.033708  0.014981       NaN  0.003745  0.007491  0.003745  \n",
      "\n",
      "[3 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analizeFreq(sentence):\n",
    "    freq = {}\n",
    "    num_letters = 0\n",
    "    for letter in sentence:\n",
    "        if ord(letter) < 65 or ord(letter) > 90:\n",
    "            continue\n",
    "        num_letters += 1\n",
    "        if letter in freq:\n",
    "            freq[letter] += 1\n",
    "        else:\n",
    "            freq[letter] = 1\n",
    "    # normalize the frequencies\n",
    "    for letter in freq:\n",
    "        freq[letter] /= num_letters\n",
    "    return freq\n",
    "\n",
    "# analizing the frequencies of the letters in each ciphered text\n",
    "freqs = [analizeFreq(x) for x in data]\n",
    "# creating a dataframe with the frequencies rows as letters and columns as frequency of each letter in each text\n",
    "df = pd.DataFrame(freqs, index=[f\"Text {i}\" for i in range(len(freqs))])\n",
    "# printing the dataframe\n",
    "print(df)\n",
    "\n",
    "combined_freq = analizeFreq(\"\".join(data))\n",
    "combined_freq = sorted(combined_freq.items(), key=lambda x: (len(x[0]), -len(x[0]), -x[1]), reverse=False)[:10]\n",
    "# creating a dataframe to compare the top 10 most frequent letters of the texts with the top 10 most frequent letters in the english language\n",
    "df_1letter = pd.DataFrame()\n",
    "df_1letter[\"T1l\"] = [x[0] for x in combined_freq]\n",
    "df_1letter[\"Txt 1 frq\"] = [x[1] for x in combined_freq]\n",
    "\n",
    "english_freq = sorted(ENGLISH_FREQ.items(), key=lambda x: (len(x[0]), -len(x[0]), -x[1]), reverse=False)[:10]\n",
    "\n",
    "df_1letter[\"E1l\"] = [x[0] for x in english_freq]\n",
    "df_1letter[\"Eng 1 frq\"] = [x[1] for x in english_freq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can notice how there is a pretty similar character frequency on all three sentences, which then leeds us to think that fortunetly the substitutions are the same for the three sentences.\n",
    "We are now going to analize letter touples to try to match the $\\mathfrak{C} \\leftrightarrow \\mathfrak{M}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WH: 0.0405\n",
      "HF: 0.0383\n",
      "FV: 0.0263\n",
      "KQ: 0.0252\n",
      "KW: 0.0197\n",
      "WF: 0.0197\n",
      "WK: 0.0175\n",
      "VF: 0.0175\n",
      "YW: 0.0164\n",
      "FY: 0.0153\n",
      "914\n"
     ]
    }
   ],
   "source": [
    "df_2letter = pd.DataFrame()\n",
    "\n",
    "def find_repeated_sequences(input_str):\n",
    "    sequence_counts = {}\n",
    "    max_sequence_length = len(input_str)\n",
    "\n",
    "    for length in range(max_sequence_length, 0, -1):\n",
    "        for start in range(max_sequence_length - length + 1):\n",
    "            sequence = input_str[start:start + length]\n",
    "            count = input_str.count(sequence)\n",
    "            if count >= 2 and len(sequence) > 1 and len(sequence) < 10:\n",
    "                sequence_counts[sequence] = count/(len(input_str)-len(sequence)+1)\n",
    "\n",
    "    sorted_sequences = sorted(sequence_counts.items(), key=lambda x: (len(x[0]), -len(x[0]), -x[1]), reverse=False)\n",
    "\n",
    "    for sequence, count in sorted_sequences[:10]:\n",
    "        print(f'{sequence}: {round(count, 4)}')\n",
    "    df_2letter[\"T2l\"] = [x[0] for x in sorted_sequences[:10]]\n",
    "    df_2letter[\"Txt 2 frq\"] = [x[1] for x in sorted_sequences[:10]]\n",
    "\n",
    "find_repeated_sequences(\"\".join(data))\n",
    "print(len(\"\".join(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare this data with real data we proceed to analyze a large amount of text that also contains no spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  T1l  Txt 1 frq E1l  Eng 1 frq\n",
      "0   F   0.137856   E      0.122\n",
      "1   W   0.124726   T      0.088\n",
      "2   K   0.079869   A      0.079\n",
      "3   Q   0.065646   O      0.072\n",
      "4   Y   0.063457   H      0.069\n",
      "5   X   0.062363   I      0.068\n",
      "6   V   0.061269   N      0.065\n",
      "7   H   0.056893   S      0.061\n",
      "8   R   0.053611   R      0.058\n",
      "9   Z   0.044858   D      0.041 \n",
      "\n",
      "  T2l  Txt 2 frq E2l  Eng 2 frq\n",
      "0  WH   0.040526  TH   0.031541\n",
      "1  HF   0.038335  HE   0.029873\n",
      "2  FV   0.026287  IN   0.019233\n",
      "3  KQ   0.025192  ER   0.019003\n",
      "4  KW   0.019715  AN   0.018187\n",
      "5  WF   0.019715  RE   0.014442\n",
      "6  WK   0.017525  ND   0.014059\n",
      "7  VF   0.017525  ED   0.013032\n",
      "8  YW   0.016429  ES   0.011904\n",
      "9  FY   0.015334  HA   0.011834\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "with open(\"sample_text.txt\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    # convert all to caps\n",
    "    text = text.upper()\n",
    "    # remove all non-alphabetic characters\n",
    "    text = re.sub(r'[^A-Z]', '', text)\n",
    "    # save the text\n",
    "    with open(\"sample_text_clean.txt\", \"w\") as f2:\n",
    "        f2.write(text)\n",
    "# analizing the frequencies of couples of  letters in text\n",
    "text_freqs = {}\n",
    "for i in range(len(text) - 1):\n",
    "    couple = text[i:i + 2]\n",
    "    if couple in text_freqs:\n",
    "        text_freqs[couple] += 1\n",
    "    else:\n",
    "        text_freqs[couple] = 1\n",
    "# normalize the frequencies\n",
    "for couple in text_freqs:\n",
    "    text_freqs[couple] /= len(text)\n",
    "# sort the frequencies\n",
    "sorted_text_freqs = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "df_2letter[\"E2l\"] = [x[0] for x in sorted_text_freqs[:10]]\n",
    "df_2letter[\"Eng 2 frq\"] = [x[1] for x in sorted_text_freqs[:10]]\n",
    "print(df_1letter, \"\\n\")\n",
    "print(df_2letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the following result:\n",
    "\n",
    "```sh\n",
    "\n",
    "  T1l  Txt 1 frq E1l  Eng 1 frq\n",
    "0   F   0.137856   E      0.122\n",
    "1   W   0.124726   T      0.088\n",
    "\n",
    "  T2l  Txt 2 frq E2l  Eng 2 frq\n",
    "0  WH   0.040526  TH   0.031541\n",
    "1  HF   0.038335  HE   0.029873\n",
    "```\n",
    "\n",
    "We conclude\n",
    "\n",
    "- $\\mathfrak{C}[H] \\equiv \\mathfrak{M}[H]$\n",
    "- $\\mathfrak{C}[W] \\equiv \\mathfrak{M}[T]$\n",
    "- $\\mathfrak{C}[F] \\equiv \\mathfrak{M}[E]$\n",
    "\n",
    "After making these substitutions we see in the text:\n",
    "```sh\n",
    "TTH_TTHETE\n",
    "WWHXWWHFWF\n",
    "```\n",
    "And we conclude that $\\mathfrak{C}[X] \\equiv \\mathfrak{M}[A]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONWRFLTIVRALHFASDBSTOTDTOINWOLHEROSAJETHICIMENWRFLTONVONKHOWHDNOTSIMLUAONTEPTARERELUAWECKOTHTHEWOLHERTEPTONACEMONECJANNERKOTHTHEHEULIMAQEFTHEDNOTSJAFBESONVUEUETTERSTHEJISTWIJJINLAORSIMUETTERSTROLUETSIMUETTERSJOPTDRESIMTHEABIGEANCSIMIRTHTHEREWEOGERCEWOLHERSTHETEPTBFLERMIRJONVTHEONGERSESDBSTOTDTOINLRIWESSTIEPTRAWTTHEIROVONAUJESSAVE\n",
      "___R__T__RA_H_A____T_T_T______HER__A_ETH____E__R__T______H__H___T_____A__TE_TARERE__A_E___THTHE___HERTE_T__A_E___E__A**ER__THTHEHE____A_E_THE___T__A__E_____E_ETTER_THE___T__**___A_R____ETTER_TR___ET____ETTER____T_RE___THEA___EA______RTHTHERE_E__ER_E___HER_THETE_T___ER__R____THE___ER_E____T_T_T____R__E**T_E_TRA_TTHE_R____A__E**A_E\n",
      "KQAVDUWRJVXUHDXYZGYWKWZWKRQAKUHFVKYXPFWHRERIFQAVDUWKQJKQSHKAHZQKWYRIUNXKQWFOWXVFVFUNXAFESKWHWHFAKUHFVWFOWKQXEFIKQFEPXQQFVSKWHWHFHFNURIXMFDWHFZQKWYPXDGFYKQJNFNFWWFVYWHFPRYWARPPRQUXKVYRINFWWFVYWVKUNFWYRINFWWFVYPKOWZVFYRIWHFXGRBFXQEYRIRVWHWHFVFAFKBFVEFAKUHFVYWHFWFOWGDUFVIRVPKQJWHFKQBFVYFYZGYWKWZWKRQUVRAFYYWRFOWVXAWWHFRVKJKQXNPFYYXJF \n",
      "\n",
      "SDBSTOTDTOINWOLHERSWANBEWIJLARECKOTHTRANSLISOTOINWOLHERSONATRANSLISOTOINWOLHERTHEDNOTSIMTHELUAONTEPTAREREARRANVECONACOMMERENTANCDSDAUUFYDOTEWIJLUEPIRCERBDTTHEDNOTSTHEJSEUGESAREUEMTDNWHANVECBFWINTRASTONASDBSTOTDTOINWOLHERTHEDNOTSIMTHELUAONTEPTARERETAONECONTHESAJESEYDENWEONTHEWOLHERTEPTBDTTHEDNOTSTHEJSEUGESAREAUTEREC\n",
      "____T_T_T______HER__A__E____ARE___THTRA______T______HER___ATRA______T______HERTHE___T___THE__A__TE_TAREREARRA__E___A__**ERE_TA_____A**____TE_____E__R_ER__TTHE___T_THE__E__E_ARE_E_T___HA__E______TRA_T__A____T_T_T______HERTHE___T___THE__A__TE_TARERETA__E___THE_A_E_E__E__E__THE___HERTE_T__TTHE___T_THE__E__E_AREA_TERE_\n",
      "YZGYWKWZWKRQAKUHFVYAXQGFARPUXVFESKWHWVXQYURYKWKRQAKUHFVYKQXWVXQYURYKWKRQAKUHFVWHFZQKWYRIWHFUNXKQWFOWXVFVFXVVXQJFEKQXEKIIFVFQWXQEZYZXNNDCZKWFARPUNFORVEFVGZWWHFZQKWYWHFPYFNBFYXVFNFIWZQAHXQJFEGDARQWVXYWKQXYZGYWKWZWKRQAKUHFVWHFZQKWYRIWHFUNXKQWFOWXVFVFWXKQFEKQWHFYXPFYFCZFQAFKQWHFAKUHFVWFOWGZWWHFZQKWYWHFPYFNBFYXVFXNWFVFE \n",
      "\n",
      "LUEASECEWICETHOSTEPTDSONVANFJETHICFIDMONCACEYDATEFIDKOUUMOVDREIDTTHATTHETEPTKASENWRFLTECDSONVTHESDBSTOTDTOINWOLHERAMTERFIDMIDNCASIUDTOINLUEASECESWROBEHIKFIDANAUFZECTHETEPTHONTFIDJAFDSEANFLRIVRAJIRSOJLUFWIDNTTHEMREYDENWOESIMAUUTHELOWTDRESTHATALLEARKOTHONTHETEPTHAGEMDN\n",
      "__EA_E_E___ETH__TE_T_____A___ETH_________A_E__ATE_____**____RE__TTHATTHETE_T_A_E__R__TE______THE____T_T_T______HERA_TER________A____T_____EA_E_E__R__EH_____A_A___E_THETE_TH__T____A___EA___R__RA__R__________TTHE_RE__E___E___A**THE___T_RE_THATA**EAR__TH__THETE_THA_E___\n",
      "UNFXYFEFAREFWHKYWFOWZYKQJXQDPFWHREDRZIKQEXEFCZXWFDRZSKNNIKJZVFRZWWHXWWHFWFOWSXYFQAVDUWFEZYKQJWHFYZGYWKWZWKRQAKUHFVXIWFVDRZIRZQEXYRNZWKRQUNFXYFEFYAVKGFHRSDRZXQXNDTFEWHFWFOWHKQWDRZPXDZYFXQDUVRJVXPRVYKPUNDARZQWWHFIVFCZFQAKFYRIXNNWHFUKAWZVFYWHXWXUUFXVSKWHKQWHFWFOWHXBFIZQ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "def substitute(sentence, map):\n",
    "    return \"\".join(map[letter] if letter in map else letter for letter in sentence)\n",
    "freqs = analizeFreq(\"\".join(data))\n",
    "\n",
    "def force_match(map, diff_map, l1, l2):\n",
    "    del diff_map[l1]\n",
    "    for k in diff_map:\n",
    "        del diff_map[k][l2]\n",
    "    map[l2] = l1\n",
    "    return map, diff_map\n",
    "\n",
    "change_to   = \"HTEAR\"\n",
    "# change_to   = \"HTERANSDOU\"\n",
    "change_from = \"HWFXV\"\n",
    "# change_from = \"HWFVKQYADR\"\n",
    "\n",
    "def find_double_letters(sentence):\n",
    "    # returns indexes\n",
    "    return [i for i in range(len(sentence)) if (i != len(sentence) - 1 and sentence[i] == sentence[i + 1]) or (i != 0 and sentence[i] == sentence[i - 1])]\n",
    "\n",
    "def matchFreq_prob_with_noise(freq1, freq2, noise_factor=0.01):\n",
    "    map = {}\n",
    "    for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "        if letter not in freq1:\n",
    "            freq1[letter] = 0\n",
    "        if letter not in freq2:\n",
    "            freq2[letter] = 0\n",
    "    freq1 = OrderedDict(sorted(freq1.items(), key=lambda x: x[0]))\n",
    "    freq2 = OrderedDict(sorted(freq2.items(), key=lambda x: x[0]))\n",
    "    diff_map = {}\n",
    "    for k1, v1 in freq1.items():\n",
    "        diff_map[k1] = {}\n",
    "        for k2, v2 in freq2.items():\n",
    "            # Add random noise to the frequency differences\n",
    "            noise = random.uniform(-noise_factor, noise_factor)\n",
    "            diff = abs(v1 - v2) + noise\n",
    "            diff_map[k1][k2] = diff\n",
    "        diff_map[k1] = OrderedDict(sorted(diff_map[k1].items(), key=lambda x: x[1]))\n",
    "\n",
    "\n",
    "    for f, t in zip(change_from, change_to):\n",
    "        map, diff_map = force_match(map, diff_map, t, f)    \n",
    "\n",
    "\n",
    "    for _ in range(len(diff_map)):\n",
    "        l1, l2 = None, None\n",
    "        # selecting the letter with the smallest difference\n",
    "        for k, v in diff_map.items():\n",
    "            if l1 is None:\n",
    "                l1 = k\n",
    "                l2 = list(v.keys())[0]\n",
    "            else:\n",
    "                if diff_map[l1][l2] > v[list(v.keys())[0]]:\n",
    "                    l1 = k\n",
    "                    l2 = list(v.keys())[0]\n",
    "        # deleting the selected letter from the map\n",
    "        del diff_map[l1]\n",
    "        for k in diff_map:\n",
    "            del diff_map[k][l2]\n",
    "        map[l2] = l1\n",
    "    return map\n",
    "for ms in range(len(data)):\n",
    "    sentence = substitute(data[ms], matchFreq_prob_with_noise(ENGLISH_FREQ, analizeFreq(\"\".join(data)), noise_factor=0))\n",
    "    repeated_letters = find_double_letters(data[ms])\n",
    "    print(sentence)\n",
    "    print(\"\".join([(x if x in change_to else (\"*\" if i in repeated_letters else \"_\")) for i, x in enumerate(sentence)]))\n",
    "    print(data[ms], \"\\n\")\n",
    "# sentence2 = substitute(\"\".join(data), matchFreq_prob_with_noise(ENGLISH_FREQ, analizeFreq(\"\".join(data)), noise_factor=0.01))\n",
    "# # print(sentence2)\n",
    "\n",
    "# # find_repeated_sequences(sentence)\n",
    "# for _ in range(10):\n",
    "#     sentence = substitute(data[ms], matchFreq_prob_with_noise(ENGLISH_FREQ, analizeFreq(\"\".join(data)), noise_factor=0.01))\n",
    "#     print(sentence)\n",
    "    # if \"OF\" in sentence:# and \"AND\" in sentence and \"OF\" in sentence and \"IT\" in sentence and \"TO\" in sentence and \"A\" in sentence and \"IN\" in sentence:\n",
    "    # with open(\"freq_map.txt\", \"a\") as f:\n",
    "    #     f.write(f\"{sentence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_double_letters(sentence):\n",
    "    # returns indexes of both letters in each pair of repeated letters\n",
    "    return [(i, i + 1) for i in range(len(sentence) - 1) if sentence[i] == sentence[i + 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_double_letters(sentence):\n",
    "    # returns indexes of both letters in each pair of repeated letters\n",
    "    return [(i, i + 1) for i in range(len(sentence) - 1) if sentence[i] == sentence[i + 1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
